{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "934ce5bb-beef-4bd6-8260-e04e3059bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2fbb9a-6e27-4cfa-95cc-95e745ff40c8",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing data\n",
    "Using TF Transform (tf.transform): single preprocesssing function runs in the batch mode; and TF Datasets (TFDS) provides many dataset resources. \n",
    "\n",
    "## 1. Data API\n",
    "create a dataset entirely in RAM using ```tf.data.Dataset.from_tensor_slices()``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3ac0326-7970-4356-83af-c9dbb803b1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 11:55:08.831389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 11:55:08.891408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 11:55:08.891553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 11:55:08.892431: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-16 11:55:08.894085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 11:55:08.894260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 11:55:08.894379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 11:55:09.210361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 11:55:09.210481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 11:55:09.210557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 11:55:09.210646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1741 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.range(10)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d84e821-eada-49d2-8109-5e9870c72add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d9c64ea-eba8-423e-a79a-23d971e37bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# repeat(3) returns a new dataset that repeats 3 times of original dataset. if no argument, it will repeat forever.\n",
    "# batch(7) group the items of dataset in batches of 7 times.\n",
    "dataset = dataset.repeat(3).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e4c402b-2daa-47b7-a86a-07b31b0d6cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n",
      "tf.Tensor([16 18], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# using map() method to transform to new dataset\n",
    "dataset = dataset.map(lambda x: x * 2)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca6dd354-3ddd-454a-80ae-b25d83c8d6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# merge all batch of dataset into scalar set.\n",
    "dataset = dataset.unbatch()\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83a48ab3-a825-4648-8a8b-b8e63d53ce42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FilterDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda x: x < 10)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5254d66-ce87-4982-a3a7-fbbcccb6116a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset.take(3):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91345f54-f66f-47cb-abb5-d354276323ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 3 0 4 2 5 6], shape=(7,), dtype=int64)\n",
      "tf.Tensor([8 7 1 0 3 2 5], shape=(7,), dtype=int64)\n",
      "tf.Tensor([4 6 9 8 9 7 0], shape=(7,), dtype=int64)\n",
      "tf.Tensor([3 1 4 5 2 8 7], shape=(7,), dtype=int64)\n",
      "tf.Tensor([6 9], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# call repeat() on the shuffled dataset, by default it will generate a new oder at every iteration.\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "dataset = tf.data.Dataset.range(10).repeat(3)\n",
    "dataset = dataset.shuffle(buffer_size=3, seed=42).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)\n",
    "    \n",
    "## if reuse the same order at each iteration (for testing or debugging), uses reshuffle_each_iteration=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2badbc80-1947-4f68-bc67-56680f8eb711",
   "metadata": {},
   "source": [
    "## 1.2. Split the dataset to multiple CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a23ba570-ed2f-417a-a2f6-cc85178a1e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_mean = scaler.mean_\n",
    "X_std = scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce2db32d-c7c7-42c4-be59-377f5f4805f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
    "    housing_dir = os.path.join(\"datasets\", \"housing\")\n",
    "    os.makedirs(housing_dir, exist_ok=True)\n",
    "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n",
    "\n",
    "    filepaths = []\n",
    "    m = len(data)\n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
    "        part_csv = path_format.format(name_prefix, file_idx)\n",
    "        filepaths.append(part_csv)\n",
    "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
    "            if header is not None:\n",
    "                f.write(header)\n",
    "                f.write(\"\\n\")\n",
    "            for row_idx in row_indices:\n",
    "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                f.write(\"\\n\")\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f1a5432-5988-4086-96be-d89520491dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.c_[X_train, y_train]\n",
    "valid_data = np.c_[X_valid, y_valid]\n",
    "test_data = np.c_[X_test, y_test]\n",
    "header_cols = housing.feature_names + [\"MedianHouseValue\"]\n",
    "header = \",\".join(header_cols)\n",
    "\n",
    "train_filepaths = save_to_multiple_csv_files(train_data, \"train\", header, n_parts=20)\n",
    "valid_filepaths = save_to_multiple_csv_files(valid_data, \"valid\", header, n_parts=10)\n",
    "test_filepaths = save_to_multiple_csv_files(test_data, \"test\", header, n_parts=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705622b0-6e05-4cbe-a05e-33de5a9b4ab1",
   "metadata": {},
   "source": [
    "## 1.3. Building an Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "928b1d7b-ac6b-4542-9872-f12b6f08ce02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file to tensor with list_files()\n",
    "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b087e6af-8135-42f5-b143-a071bbfece60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call interleave() to read from 5 files at a time, skip the first line with skip()\n",
    "\n",
    "n_readers = 5\n",
    "dataset = filepath_dataset.interleave(\n",
    "    lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "    cycle_length=n_readers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b0bf5d7-2570-44e3-aba0-6af4eb3d133c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'4.7361,7.0,7.464968152866242,1.1178343949044587,846.0,2.694267515923567,34.49,-117.27,1.745'\n",
      "b'3.6641,17.0,5.577142857142857,1.1542857142857144,511.0,2.92,40.85,-121.07,0.808'\n",
      "b'4.5909,16.0,5.475877192982456,1.0964912280701755,1357.0,2.9758771929824563,33.63,-117.71,2.418'\n",
      "b'3.6875,44.0,4.524475524475524,0.993006993006993,457.0,3.195804195804196,34.04,-118.15,1.625'\n",
      "b'2.3,25.0,5.828178694158075,0.9587628865979382,909.0,3.1237113402061856,36.25,-119.4,1.328'\n"
     ]
    }
   ],
   "source": [
    "# now, the training dataset is the TextLineDataset\n",
    "for line in dataset.take(5):\n",
    "    print(line.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce7b15e4-1a56-4a24-b002-7b5d3a0e510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 8 # X_train.shape[-1]\n",
    "\n",
    "@tf.function\n",
    "def preprocess(line):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    return (x - X_mean) / X_std, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6341d3fe-6607-4a59-b560-af9dc86123f0",
   "metadata": {},
   "source": [
    "- Assumes we have precomputed mean (X_mean) and standard deviation (X_std) of each feature in the training set.\n",
    "- The preprocess() takes one csv line and start parsing it by using ```tf.io.decode_csv()``` with 2 arguments: the line to parse, and the default value for each column. First we want an array of 8 float values, and their default is 0. if there have some missed values. And the last column is empty with no default value, and the type is float32 as default type, so it will raise an exception if it encounters a missing value.\n",
    "- the decode_csv returns the scalar tensors, but we need the 1D tensor. So we call stack() to make this scalar into a 1D array.\n",
    "- Finally, we scale all input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a7efe27-bfef-4c02-9b39-5a9df27e9e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       " array([ 0.39593136,  0.74167496, -0.16415128, -0.40340805, -0.61991787,\n",
       "        -0.18355484, -1.4084505 ,  1.2565969 ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.504], dtype=float32)>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(b'4.6477,38.0,5.03728813559322,0.911864406779661,745.0,2.5254237288135593,32.64,-117.07,1.504')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "971cde5b-5b47-44e7-929e-12f56cbd137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## final all things\n",
    "def csv_reader_dataset(filepaths, repeat=1, n_readers=5,\n",
    "                       n_read_threads=None, shuffle_buffer_size=10000,\n",
    "                       n_parse_threads=5, batch_size=32):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3909e9-b40d-44a8-8590-0ba1c06ccdc3",
   "metadata": {},
   "source": [
    "- prefetch() to create dataset that has one batch ahead.\n",
    "- Check all methods for dataset preprocessing: tf.data.experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ada60ae-f249-4147-9f9d-ef669f6c3b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = tf.Tensor(\n",
      "[[ 0.5804519  -0.20762321  0.05616303 -0.15191229  0.01343246  0.00604472\n",
      "   1.2525111  -1.3671792 ]\n",
      " [ 5.818099    1.8491895   1.1784915   0.28173092 -1.2496178  -0.3571987\n",
      "   0.7231292  -1.0023477 ]\n",
      " [-0.9253566   0.5834586  -0.7807257  -0.28213993 -0.36530012  0.27389365\n",
      "  -0.76194876  0.72684526]], shape=(3, 8), dtype=float32)\n",
      "y = tf.Tensor(\n",
      "[[1.752]\n",
      " [1.313]\n",
      " [1.535]], shape=(3, 1), dtype=float32)\n",
      "\n",
      "X = tf.Tensor(\n",
      "[[-0.8324941   0.6625668  -0.20741376 -0.18699841 -0.14536144  0.09635526\n",
      "   0.9807942  -0.67250353]\n",
      " [-0.62183803  0.5834586  -0.19862501 -0.3500319  -1.1437552  -0.3363751\n",
      "   1.107282   -0.8674123 ]\n",
      " [ 0.8683102   0.02970133  0.3427381  -0.29872298  0.7124906   0.28026953\n",
      "  -0.72915536  0.86178064]], shape=(3, 8), dtype=float32)\n",
      "y = tf.Tensor(\n",
      "[[0.919]\n",
      " [1.028]\n",
      " [2.182]], shape=(3, 1), dtype=float32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "train_set = csv_reader_dataset(train_filepaths, batch_size=3)\n",
    "for X_batch, y_batch in train_set.take(2):\n",
    "    print(\"X =\", X_batch)\n",
    "    print(\"y =\", y_batch)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4109d829-0a4c-4348-b356-e9e747515122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# completely read data from csv files\n",
    "train_set = csv_reader_dataset(train_filepaths, repeat=None)\n",
    "valid_set = csv_reader_dataset(valid_filepaths)\n",
    "test_set = csv_reader_dataset(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87d44b32-5933-4e00-bade-bb6328e6efe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a sequential model\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ccab170-385a-4afb-8d75-fd8f88138196",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 11:55:10.503230: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2aac51c250>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(train_set, steps_per_epoch=len(X_train) // batch_size, epochs=10,\n",
    "          validation_data=valid_set, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46cdfa87-e8f0-45c7-98de-e5d126206b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 0s 616us/step - loss: 0.4788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47877517342567444"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set, steps=len(X_test) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4ca9dac-724f-4115-8be7-beac18a0b50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.8256307],\n",
       "       [2.41031  ],\n",
       "       [1.0489031],\n",
       "       ...,\n",
       "       [3.1952968],\n",
       "       [1.4562888],\n",
       "       [3.1594508]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_set = test_set.map(lambda X, y: X) # we could instead just pass test_set, Keras would ignore the labels\n",
    "X_new = X_test\n",
    "model.predict(new_set, steps=len(X_new) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44ad7c80-59a4-4c64-b7bf-4401b2496ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step 100 / 1810\n",
      "Global step 200 / 1810\n",
      "Global step 300 / 1810\n",
      "Global step 400 / 1810\n",
      "Global step 500 / 1810\n",
      "Global step 600 / 1810\n",
      "Global step 700 / 1810\n",
      "Global step 800 / 1810\n",
      "Global step 900 / 1810\n",
      "Global step 1000 / 1810\n",
      "Global step 1100 / 1810\n",
      "Global step 1200 / 1810\n",
      "Global step 1300 / 1810\n",
      "Global step 1400 / 1810\n",
      "Global step 1500 / 1810\n",
      "Global step 1600 / 1810\n",
      "Global step 1700 / 1810\n",
      "Global step 1800 / 1810\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "## build a custom training loop\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "@tf.function\n",
    "def train(model, n_epochs, batch_size=32,\n",
    "          n_readers=5, n_read_threads=5, shuffle_buffer_size=10000, n_parse_threads=5):\n",
    "    train_set = csv_reader_dataset(train_filepaths, repeat=n_epochs, n_readers=n_readers,\n",
    "                       n_read_threads=n_read_threads, shuffle_buffer_size=shuffle_buffer_size,\n",
    "                       n_parse_threads=n_parse_threads, batch_size=batch_size)\n",
    "    n_steps_per_epoch = len(X_train) // batch_size\n",
    "    total_steps = n_epochs * n_steps_per_epoch\n",
    "    global_step = 0\n",
    "    for X_batch, y_batch in train_set.take(total_steps):\n",
    "        global_step += 1\n",
    "        if tf.equal(global_step % 100, 0):\n",
    "            tf.print(\"\\rGlobal step\", global_step, \"/\", total_steps)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "train(model, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e28c604-d1e1-424a-bb31-3df12dd98cef",
   "metadata": {},
   "source": [
    "## 2. TFRecord format\n",
    "Other way to use Data API, create a TFRecord file using the tf.io.TFRecordWriter class:\n",
    "```\n",
    "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
    "    f.write(b\"This is the first record\")\n",
    "    f.write(b\"And this is the second record\")\n",
    "```\n",
    "\n",
    "Read data from TFRecord\n",
    "```\n",
    "filepaths = [\"my_data.tfrecord\"]\n",
    "dataset = tf.data.TFRecordDataset(filepaths)\n",
    "for item in dataset:\n",
    "    print(item)\n",
    "```\n",
    "\n",
    "You can read multiple TFRecord files with just one TFRecordDataset. By default it will read them one at a time, but if you set num_parallel_reads=3, it will read 3 at a time in parallel and interleave their records:\n",
    "```\n",
    "dataset = tf.data.TFRecordDataset(filepaths, num_parallel_reads=3)\n",
    "for item in dataset:\n",
    "    print(item)\n",
    "```\n",
    "\n",
    "We can compress file with compression_type\n",
    "```\n",
    "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
    "with tf.io.TFRecordWriter(\"my_compressed.tfrecord\", options) as f:\n",
    "    f.write(b\"This is the first record\")\n",
    "    f.write(b\"And this is the second record\")\n",
    "```\n",
    "and read compressed file:\n",
    "```\n",
    "dataset = tf.data.TFRecordDataset([\"my_compressed.tfrecord\"], compression_type=\"GZIP\")\n",
    "for item in dataset:\n",
    "    print(item)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ef263e-e41a-4ad0-9399-b3c4d0b58ddf",
   "metadata": {},
   "source": [
    "a.\n",
    "_Exercise: Load the Fashion MNIST dataset (introduced in Chapter 10); split it into a training set, a validation set, and a test set; shuffle the training set; and save each dataset to multiple TFRecord files. Each record should be a serialized Example protobuf with two features: the serialized image (use tf.io.serialize_tensor() to serialize each image), and the label. Note: for large images, you could use tf.io.encode_jpeg() instead. This would save a lot of space, but it would lose a bit of image quality._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c63c617-a663-4a5a-812a-0c828e7009ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc1c72cd-398f-4414-bc6b-b21bf712acd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# using TF training\n",
    "BytesList = tf.train.BytesList\n",
    "FloatList = tf.train.FloatList\n",
    "Int64List = tf.train.Int64List\n",
    "Feature = tf.train.Feature\n",
    "Features = tf.train.Features\n",
    "Example = tf.train.Example\n",
    "FeatureList = tf.train.FeatureList\n",
    "FeatureLists = tf.train.FeatureLists\n",
    "SequenceExample = tf.train.SequenceExample\n",
    "\n",
    "train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train))\n",
    "valid_set = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
    "test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e002a8b-f914-4418-a2c9-cdb52c130636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example(image, label):\n",
    "    image_data = tf.io.serialize_tensor(image)\n",
    "    #image_data = tf.io.encode_jpeg(image[..., np.newaxis])\n",
    "    return Example(\n",
    "        features=Features(\n",
    "            feature={\n",
    "                \"image\": Feature(bytes_list=BytesList(value=[image_data.numpy()])),\n",
    "                \"label\": Feature(int64_list=Int64List(value=[label])),\n",
    "            }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce99ee45-ef47-487f-8663-e201eaae527b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"image\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"\\010\\004\\022\\010\\022\\002\\010\\034\\022\\002\\010\\034\\\"\\220\\006\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000\\000\\rI\\000\\000\\001\\004\\000\\000\\000\\000\\001\\001\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\003\\000$\\210\\177>6\\000\\000\\000\\001\\003\\004\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\006\\000f\\314\\260\\206\\220{\\027\\000\\000\\000\\000\\014\\n\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\233\\354\\317\\262k\\234\\241m@\\027M\\202H\\017\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000E\\317\\337\\332\\330\\330\\243\\177yz\\222\\215X\\254B\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\001\\001\\000\\310\\350\\350\\351\\345\\337\\337\\327\\325\\244\\177{\\304\\345\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\267\\341\\330\\337\\344\\353\\343\\340\\336\\340\\335\\337\\365\\255\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\301\\344\\332\\325\\306\\264\\324\\322\\323\\325\\337\\334\\363\\312\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\003\\000\\014\\333\\334\\324\\332\\300\\251\\343\\320\\332\\340\\324\\342\\305\\3214\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\006\\000c\\364\\336\\334\\332\\313\\306\\335\\327\\325\\336\\334\\365w\\2478\\000\\000\\000\\000\\000\\000\\000\\000\\000\\004\\000\\0007\\354\\344\\346\\344\\360\\350\\325\\332\\337\\352\\331\\331\\321\\\\\\000\\000\\000\\001\\004\\006\\007\\002\\000\\000\\000\\000\\000\\355\\342\\331\\337\\336\\333\\336\\335\\330\\337\\345\\327\\332\\377M\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000>\\221\\314\\344\\317\\325\\335\\332\\320\\323\\332\\340\\337\\333\\327\\340\\364\\237\\000\\000\\000\\000\\000\\022,Rk\\275\\344\\334\\336\\331\\342\\310\\315\\323\\346\\340\\352\\260\\274\\372\\370\\351\\356\\327\\000\\0009\\273\\320\\340\\335\\340\\320\\314\\326\\320\\321\\310\\237\\365\\301\\316\\337\\377\\377\\335\\352\\335\\323\\334\\350\\366\\000\\003\\312\\344\\340\\335\\323\\323\\326\\315\\315\\315\\334\\360P\\226\\377\\345\\335\\274\\232\\277\\322\\314\\321\\336\\344\\341\\000b\\351\\306\\322\\336\\345\\345\\352\\371\\334\\302\\327\\331\\361AIju\\250\\333\\335\\327\\331\\337\\337\\340\\345\\035K\\314\\324\\314\\301\\315\\323\\341\\330\\271\\305\\316\\306\\325\\360\\303\\343\\365\\357\\337\\332\\324\\321\\336\\334\\335\\346C0\\313\\267\\302\\325\\305\\271\\276\\302\\300\\312\\326\\333\\335\\334\\354\\341\\330\\307\\316\\272\\265\\261\\254\\265\\315\\316s\\000z\\333\\301\\263\\253\\267\\304\\314\\322\\325\\317\\323\\322\\310\\304\\302\\277\\303\\277\\306\\300\\260\\234\\247\\261\\322\\\\\\000\\000J\\275\\324\\277\\257\\254\\257\\265\\271\\274\\275\\274\\301\\306\\314\\321\\322\\322\\323\\274\\274\\302\\300\\330\\252\\000\\002\\000\\000\\000B\\310\\336\\355\\357\\362\\366\\363\\364\\335\\334\\301\\277\\263\\266\\266\\265\\260\\246\\250c:\\000\\000\\000\\000\\000\\000\\000\\000\\000(=,H)#\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 9\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for image, label in valid_set.take(1):\n",
    "    print(create_example(image, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "885fa5fc-3634-468f-9d23-7ac078753ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset to a set of TFRecord files, the examples are written to the file in round-robin fashion. \n",
    "# use dataset.enumerate() all examples, and index % n_shards to decide which file to write to.\n",
    "# use the standard contextlib.ExitStack class to make sure all writers are closed whether or not an I/O error\n",
    "from contextlib import ExitStack\n",
    "\n",
    "def write_tfrecords(name, dataset, n_shards=10):\n",
    "    paths = [\"{}.tfrecord-{:05d}-of-{:05d}\".format(name, index, n_shards)\n",
    "             for index in range(n_shards)]\n",
    "    with ExitStack() as stack:\n",
    "        writers = [stack.enter_context(tf.io.TFRecordWriter(path))\n",
    "                   for path in paths]\n",
    "        for index, (image, label) in dataset.enumerate():\n",
    "            shard = index % n_shards\n",
    "            example = create_example(image, label)\n",
    "            writers[shard].write(example.SerializeToString())\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2319b57-70a2-452f-9959-316e77dbe5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_dir = os.path.join(\"datasets\", \"fashion_mnist\")\n",
    "os.makedirs(fashion_dir, exist_ok=True)\n",
    "\n",
    "train_filepaths = write_tfrecords(os.path.join(fashion_dir, \"my_fashion_mnist.train\"), train_set)\n",
    "valid_filepaths = write_tfrecords(os.path.join(fashion_dir, \"my_fashion_mnist.valid\"), valid_set)\n",
    "test_filepaths = write_tfrecords(os.path.join(fashion_dir, \"my_fashion_mnist.test\"), test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5714d24e-5874-44f6-90e3-7cc7ebef7693",
   "metadata": {},
   "source": [
    "Then use tf.data to create an efficient dataset for each set. Finally, use a Keras model to train these datasets, including a preprocessing layer to standardize each input feature. Try to make the input pipeline as efficient as possible, using TensorBoard to visualize profiling data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6580a410-852f-4912-a69f-e4d9b48eec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tfrecord):\n",
    "    feature_descriptions = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64, default_value=-1)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(tfrecord, feature_descriptions)\n",
    "    image = tf.io.parse_tensor(example[\"image\"], out_type=tf.uint8)\n",
    "    #image = tf.io.decode_jpeg(example[\"image\"])\n",
    "    image = tf.reshape(image, shape=[28, 28])\n",
    "    return image, example[\"label\"]\n",
    "\n",
    "def mnist_dataset(filepaths, n_read_threads=5, shuffle_buffer_size=None,\n",
    "                  n_parse_threads=5, batch_size=32, cache=True):\n",
    "    dataset = tf.data.TFRecordDataset(filepaths,\n",
    "                                      num_parallel_reads=n_read_threads)\n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3477901d-823a-46b4-a54f-2708f154ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = mnist_dataset(train_filepaths, shuffle_buffer_size=60000)\n",
    "valid_set = mnist_dataset(valid_filepaths)\n",
    "test_set = mnist_dataset(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5d62c78-cde7-4233-a879-da12705a367d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for X, y in train_set.take(1):\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(X[i].numpy(), cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(str(y[i].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "469dcdc0-1fbe-4ea3-8270-2cbb2e72fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "class Standardization(keras.layers.Layer):\n",
    "    def adapt(self, data_sample):\n",
    "        self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
    "        self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
    "    def call(self, inputs):\n",
    "        return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())\n",
    "\n",
    "standardization = Standardization(input_shape=[28, 28])\n",
    "# or perhaps soon:\n",
    "#standardization = keras.layers.Normalization()\n",
    "\n",
    "sample_image_batches = train_set.take(100).map(lambda image, label: image)\n",
    "sample_images = np.concatenate(list(sample_image_batches.as_numpy_iterator()),\n",
    "                               axis=0).astype(np.float32)\n",
    "standardization.adapt(sample_images)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    standardization,\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"nadam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bea916f6-9064-4d0b-8694-785236dd6281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 00:45:45.478763: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-04-17 00:45:45.478821: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-04-17 00:45:45.479569: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1630] Profiler found 1 GPUs\n",
      "2022-04-17 00:45:45.480496: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 00:45:45.703821: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2022-04-17 00:45:45.704023: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1764] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10/Unknown - 0s 20ms/step - loss: 1.7790 - accuracy: 0.3844     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 00:45:46.034443: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-04-17 00:45:46.034463: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-04-17 00:45:46.174596: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2022-04-17 00:45:46.174861: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1764] CUPTI activity buffer flushed\n",
      "2022-04-17 00:45:46.184371: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 152 callback api events and 151 activity events. \n",
      "2022-04-17 00:45:46.186670: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2022-04-17 00:45:46.191223: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./my_logs/run_20220417_004545/plugins/profile/2022_04_17_00_45_46\n",
      "\n",
      "2022-04-17 00:45:46.193185: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to ./my_logs/run_20220417_004545/plugins/profile/2022_04_17_00_45_46/G15.trace.json.gz\n",
      "2022-04-17 00:45:46.198928: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./my_logs/run_20220417_004545/plugins/profile/2022_04_17_00_45_46\n",
      "\n",
      "2022-04-17 00:45:46.199501: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to ./my_logs/run_20220417_004545/plugins/profile/2022_04_17_00_45_46/G15.memory_profile.json.gz\n",
      "2022-04-17 00:45:46.199686: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./my_logs/run_20220417_004545/plugins/profile/2022_04_17_00_45_46\n",
      "Dumped tool data for xplane.pb to ./my_logs/run_20220417_004545/plugins/profile/2022_04_17_00_45_46/G15.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./my_logs/run_20220417_004545/plugins/profile/2022_04_17_00_45_46/G15.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./my_logs/run_20220417_004545/plugins/profile/2022_04_17_00_45_46/G15.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./my_logs/run_20220417_004545/plugins/profile/2022_04_17_00_45_46/G15.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./my_logs/run_20220417_004545/plugins/profile/2022_04_17_00_45_46/G15.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 3s 1ms/step - loss: 566.4320 - accuracy: 0.8424 - val_loss: 940.7704 - val_accuracy: 0.8678\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 315.8905 - accuracy: 0.8779 - val_loss: 2336.2422 - val_accuracy: 0.8782\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 168.5862 - accuracy: 0.8927 - val_loss: 1350.8655 - val_accuracy: 0.8630\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 420.5074 - accuracy: 0.9002 - val_loss: 740.9476 - val_accuracy: 0.8814\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 194.0446 - accuracy: 0.9065 - val_loss: 950.6796 - val_accuracy: 0.8850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2aa4e54b80>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "logs = os.path.join(os.curdir, \"my_logs\",\n",
    "                    \"run_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logs, histogram_freq=1, profile_batch=10)\n",
    "\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set,\n",
    "          callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62313ade-fcde-4d57-abea-0fa280b12e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e8c8b111bbde40e9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e8c8b111bbde40e9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697ad457",
   "metadata": {},
   "source": [
    "Exercise: In this exercise you will download a dataset, split it, create a tf.data.Dataset to load it and preprocess it efficiently, then build and train a binary classification model containing an Embedding layer.\n",
    "\n",
    "### a.\n",
    "Exercise: Download the Large Movie Review Dataset, which contains 50,000 movies reviews from the Internet Movie Database. The data is organized in two directories, train and test, each containing a pos subdirectory with 12,500 positive reviews and a neg subdirectory with 12,500 negative reviews. Each review is stored in a separate text file. There are other files and folders (including preprocessed bag-of-words), but we will ignore them in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13b0a2a2-ae7f-4dff-92c5-6b51db225a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "84131840/84125825 [==============================] - 197s 2us/step\n",
      "84140032/84125825 [==============================] - 197s 2us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/chuongnet/.keras/datasets/aclImdb')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DOWNLOAD_ROOT = \"http://ai.stanford.edu/~amaas/data/sentiment/\"\n",
    "FILENAME = \"aclImdb_v1.tar.gz\"\n",
    "filepath = keras.utils.get_file(FILENAME, DOWNLOAD_ROOT + FILENAME, extract=True)\n",
    "path = Path(filepath).parent / \"aclImdb\"\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c6afded-db4e-4d2b-9b56-ce9cd24647eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclImdb/\n",
      "    README\n",
      "    imdb.vocab\n",
      "    imdbEr.txt\n",
      "    train/\n",
      "        labeledBow.feat\n",
      "        unsupBow.feat\n",
      "        urls_neg.txt\n",
      "        ...\n",
      "        neg/\n",
      "            0_3.txt\n",
      "            10000_4.txt\n",
      "            10001_4.txt\n",
      "            ...\n",
      "        pos/\n",
      "            0_9.txt\n",
      "            10000_8.txt\n",
      "            10001_10.txt\n",
      "            ...\n",
      "        unsup/\n",
      "            0_0.txt\n",
      "            10000_0.txt\n",
      "            10001_0.txt\n",
      "            ...\n",
      "    test/\n",
      "        labeledBow.feat\n",
      "        urls_neg.txt\n",
      "        urls_pos.txt\n",
      "        neg/\n",
      "            0_2.txt\n",
      "            10000_4.txt\n",
      "            10001_1.txt\n",
      "            ...\n",
      "        pos/\n",
      "            0_10.txt\n",
      "            10000_7.txt\n",
      "            10001_9.txt\n",
      "            ...\n"
     ]
    }
   ],
   "source": [
    "for name, subdirs, files in os.walk(path):\n",
    "    indent = len(Path(name).parts) - len(path.parts)\n",
    "    print(\"    \" * indent + Path(name).parts[-1] + os.sep)\n",
    "    for index, filename in enumerate(sorted(files)):\n",
    "        if index == 3:\n",
    "            print(\"    \" * (indent + 1) + \"...\")\n",
    "            break\n",
    "        print(\"    \" * (indent + 1) + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0242644-846e-495f-baa7-04441159304b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 12500, 12500, 12500)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading data\n",
    "def review_paths(dirpath):\n",
    "    return [str(path) for path in dirpath.glob(\"*.txt\")]\n",
    "\n",
    "train_pos = review_paths(path / \"train\" / \"pos\")\n",
    "train_neg = review_paths(path / \"train\" / \"neg\")\n",
    "test_valid_pos = review_paths(path / \"test\" / \"pos\")\n",
    "test_valid_neg = review_paths(path / \"test\" / \"neg\")\n",
    "\n",
    "len(train_pos), len(train_neg), len(test_valid_pos), len(test_valid_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26ea8ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split the test set into a validation set and test set\n",
    "np.random.shuffle(test_valid_pos)\n",
    "\n",
    "test_pos = test_valid_pos[:5000]\n",
    "test_neg = test_valid_neg[:5000]\n",
    "valid_pos = test_valid_pos[5000:]\n",
    "valid_neg = test_valid_neg[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32910f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 16:14:03.332109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-17 16:14:03.361113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-17 16:14:03.361217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-17 16:14:03.361846: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-17 16:14:03.362903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-17 16:14:03.363003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-17 16:14:03.363081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-17 16:14:03.641457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-17 16:14:03.641579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-17 16:14:03.641656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-17 16:14:03.641739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1750 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.74 s  0 ns per loop (mean  std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "## use tf.data to create an efficient dataset \n",
    "def imdb_dataset(filepaths_positive, filepaths_negative):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    for filepaths, label in ((filepaths_negative, 0), (filepaths_positive, 1)):\n",
    "        for filepath in filepaths:\n",
    "            with open(filepath) as review_file:\n",
    "                reviews.append(review_file.read())\n",
    "            labels.append(label)\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        (tf.constant(reviews), tf.constant(labels)))\n",
    "\n",
    "%timeit -r1 for X, y in imdb_dataset(train_pos, train_neg).repeat(10): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5ed6bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.2 s  0 ns per loop (mean  std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "## if very large data, using the TFRecord, and TextLineDataSet() to read line by line\n",
    "def imdb_dataset(filepaths_positive, filepaths_negative, n_read_threads=5):\n",
    "    dataset_neg = tf.data.TextLineDataset(filepaths_negative,\n",
    "                                          num_parallel_reads=n_read_threads)\n",
    "    dataset_neg = dataset_neg.map(lambda review: (review, 0))\n",
    "    dataset_pos = tf.data.TextLineDataset(filepaths_positive,\n",
    "                                          num_parallel_reads=n_read_threads)\n",
    "    dataset_pos = dataset_pos.map(lambda review: (review, 1))\n",
    "    return tf.data.Dataset.concatenate(dataset_pos, dataset_neg)\n",
    "\n",
    "%timeit -r1 for X, y in imdb_dataset(train_pos, train_neg).repeat(10): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebe080e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.42 s  0 ns per loop (mean  std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "## So, it must be reloaded at each epoch. If we add .cache() just before repeat(10)\n",
    "%timeit -r1 for X, y in imdb_dataset(train_pos, train_neg).cache().repeat(10): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b14724bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## prefetch dataset with shuffle for train, test, and valid set\n",
    "batch_size = 32\n",
    "\n",
    "train_set = imdb_dataset(train_pos, train_neg).shuffle(25000).batch(batch_size).prefetch(1)\n",
    "valid_set = imdb_dataset(valid_pos, valid_neg).batch(batch_size).prefetch(1)\n",
    "test_set = imdb_dataset(test_pos, test_neg).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8aecf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'Gender Bender the Limerick:<br /><br />A man or a woman? Who knows?<br /><br />It turns out that \\'it\\' is both.<br /><br />Sleeping in clay<br /><br />Then they all went away<br /><br />In one of their UFOs.<br /><br />Gender Bender is another great Season 1 episode. I enjoy this one because the story is the kind where you are never really sure what\\'s gonna happen next. It is entirely original. The teaser is very fun with the close up of the eye and the reflection of the disco lights. I really need to learn my that thumb trick the genderbender heshe does. I really like the atmosphere at the Kindred\\'s little village and Mulder and Scully sneaking around in the middle of the night. Its very exciting. This is one of my favorite Season 1 episodes in fact. I think the thing I like about it so much is how they turn out to be aliens in the end and left crop circles. Many people see this as a non-mythology related alien episode kind of like \"The Unnatural\" or \"Space\" but I think this could easily be seen as mythology related. Maybe the genderbender was just like the alien bounty hunter and could appear to look like anyone. Huh? Anyway I give the episode a 9 out of 10.',\n",
      "       b'Better than the typical made-for-tv movie, INVITATION TO HELL is blessed with excellent casting (Urich, Lucci, Cassidy, McCarthy, pre-Murphy Brown Joe Regalbuto, Soleil Moon-Frye) and a high concept update to the familiar Faustian plot. Urich is likable as always and Lucci is particularly fetching and devilishly over the top in the mother of all femme fatale roles. Kind of a hybrid version of STEPFORD WIVES and THEY LIVE, the movie commits early to its apocalyptic Miltonesque vision and horror fans will likely not have many complaints until the soppy, maudlin denoument. 7/10',\n",
      "       b\"This film surprised me a little. I watch a lot of horror/sci-fi films and this is a straight-to-video release that caught me off guard a little. I believe this is Full Moon's best movie thus far and one of Jeffrey Combs best performances. Good movie.\",\n",
      "       b'For those who like depressing films with sleazy characters and a sordid storyline, this one is for you! From the bleak New York City atmosphere, which comes across as an extremely grim and almost hopeless place, to two diverse lead characters devoid of much sense of morality, this movie is a real downer. <br /><br />Why it won the Academy Award was because it was so shocking at that time that Hollywood, brand new its freedom to show anything it wanted with all moral codes abandoned, wanted to celebrate that fact. Filmmakers then were like an immature six-year-old with an unlimited expense account at the local candy store. So, Hollywood gave theater viewers (for probably the first time) a dose of rape, prostitution, homosexuality, child nudity, homeless existence and other such wonderful sights and sounds only its twisted brain would think is appealing....and then awarded its work. <br /><br />It also hoped, I\\'m sure, to shock mainstream audiences. Well, it succeeded on that level. Audiences were stunned at what they say and heard and the Academy, proud of itself for being able to display filth and make money at the same time, couldn\\'t help but bestow honors upon this piece of gilded garbage.<br /><br />Forty years ago, as a very young man, I found this film fascinating, too. However, seeing it again in the 1990s left such a bad taste in my mouth I never watched to view it again. <br /><br />The acting was good, but so what? Acting is good in many films. Nobody ever said Dustin Hoffman and Jon Voight couldn\\'t act. Hoffman was particularly good in his younger days in playing wacked-out people. He was kind of like the Johnny Depp of his era, playing guys like \"Ratso Rizzo\" in this film and then going to be the \"Rain Man\" later on. Yes, \"Ratso\" is a character you\\'ll never forget, and \"Joe Buck\" (Voight) is one you want to forget, but the story is so sordid, it overwhelms the fine acting.<br /><br />This movie isn\\'t \"art,\" and it isn\\'t worthy of its many awards; it only pushed the envelope big-time in 1969 and that\\'s why it is so fondly remembered in the hearts of film people and critics. It\\'s two hours of profanity and ultra-sleazy, religious cheap shots, glorifying weirdos (Andy Warhol even gets in the act - no surprise), and generally despicable people.<br /><br />I did like the catchy song, \"Everybody\\'s Talking\\'\" that helped make Harry Nilsson famous, but even that was bogus because Fred Neil wrote the song and sang it better, before Nilsson did it....and few people have ever heard of Neil (which is their loss). And - as mentioned - the name \"Ratso Rizzo\" kind of stays with you!<br /><br />The film is a landmark, but in a negative sense, I fear: this marked it as \"official\" that Hollywood had gone down the toilet, and it has remained in the sewer ever since.',\n",
      "       b'Probably Bigas Luna\\'s finest achievement for it achieves a delicate balance between sleaze, eroticism and surrealism. The delicious Mathilda May, who spent most of Tobe Hooper\\'s \"Lifeforce\" in the buff, is the object of young Biel Duran\\'s pre-teen lust. He can\\'t get May\\'s breasts out of his mind and wants so badly to suckle them and suckle the breasts of his own mother, too. His pursuit of May IS the film. As in Luna works such as \"Lulu\" and \"Jamon! Jamon!\", the director brings a slightly warped sexual sensibility to his strange but beautiful tale. The usual suspects will be offended, but those with open minds will enjoy this frothy erotic poem to the female breast. Jos\\xc3\\xa9 Luis Alcaine\\'s images are gorgeous and Nicola Piovani\\'s score is sweet and rich. A gorgeous cinematic confection with a delightfully anarchic sensibility that the Spanish do so naturally.',\n",
      "       b'Documentary about nomadic Persians making a treacherous traverse of massive mountains to get their herds to grass. Watching this silent, black and white feature, marred in part by a twink-twink-twink Oriental music score that could not have been used in the original exhibition, is even duller than it sounds. The spectacular scenery is lost on a small black and white screen, and there is an utter failure to establish any kind of plot line. I loved Nanook of the North and March of the Penguins, but despised this movie, notwithstanding the similarity of the theme. Physical hardships alone are just not that interesting.',\n",
      "       b'Movie \"comedies\" nowadays are generally 100 minutes of toilet humor, foul language, and groin-kicking. Modern comedies appeal to the lowest common denominator, the undemanding and slow of brain. Sure, an occasional good comedy will come along, but they\\'re becoming rarer all the time.<br /><br />\"Mr. Blandings Buildings his Dream House\" shows what 1940s Hollywood was capable of, and it\\'s just screamingly funny. Jim and Muriel Blandings (Cary Grant and Myrna Loy) decide to build a house in the Connecticut suburbs. The film follows their story, beginning with house hunting trips, the house\\'s riotous construction, all the way to the finished home--with its \"zuzz-zuzz water softener\".<br /><br />Grant and Loy are perfect for their roles, of course (Grant is particularly funny as he watches the house\\'s costs zoom out of control). However, the film is stolen by the Blandings\\' wise attorney, played to perfection by Melvyn Douglas. Managing to steal every scene he\\'s in, Douglas is understatedly hilarious while he watches the Blandings lurch from crisis to crisis. Reginald Denny as the Blandings\\' harried architect and Harry Shannon as the crusty old water well driller are also wonderful.<br /><br />I\\'ve watched this movie numerous times and it always makes me laugh. I think it\\'s a good film to watch when you need a lift, whether you\\'re building a house or not.',\n",
      "       b'Loyalty to Peter Falk is all that kept me from giving this awful picture the (1) it deserved. (For that matter, loyalty to Mr. Falk was what kept me watching this film all the way from heads to tails.) Even if you forgive all the glaring errors, this was just plain the poorest excuse for a made-for-TV \"Columbo\" film ever. I\\'m glad I watched it on TV for free; would have hated to have coughed up the bucks for a print.',\n",
      "       b'With a movie called \"Gayniggers from Outer Space\" how could you go wrong? Just throw in some over the top stereotypes for the characters, use the Village People as the main suppliers for the soundtrack, and throw in tons of gay-gags. Plot is unimportant. Too bad, this film doesn\\'t contain any of this and every joke misses the spot. The characters all look alike apart from the german gaynigger, one or two jokes work, the rest fails.<br /><br />The title made me laugh and I was prepared to laugh even more about the film. My expectation were to high apparently.',\n",
      "       b'The script was VERY weak w/o enough character arcs to make you care one bit about the characters or what happens to them. The script is way too talky and not enough gore or action to even call it slow paced. The story gets to the point that you just want everyone to shut up and die as quickly as possible so you don\\'t have to listen to them talk this very muted, stiff dialogue. On a technical note, the music mix is way to high and makes it hard to understand what is being said most times. Then again, this could be called a blessing. Overall, this same story could have better been told in a short film w/ a running time under 30 minutes. The obvious \"in your face\" homages to Sam Raimi and \"Evil Dead\" would have been good had they been more subtle, but here they seem more like a bald faced rip off. C\\'mon, this kind of 35mm budget and THIS is the best that could be done? Still, the cinematography, lighting design and shots were very well done indeed.',\n",
      "       b'After reading the comments to this movie and seeing the mixed reviews, I decided that I would add my ten cents worth to say I thought the film was excellent, not only in the visual beauty, the writing, music score, acting, and directing, but in putting across the story of Joseph Smith and the road he traveled through life of hardship and persecution for believing in God the way he felt and knew to be his path. I am very pleased, indeed, to have had a small part in telling the story of this remarkable man. I recommend everyone to see this when the opportunity presents itself, no matter what religious path he or she may be walking, this only instills one with more determination to live the life that we should with true values of love and forgiveness as the Savior taught us to do.',\n",
      "       b\"where would one start a review of the film Snitch'd? James Cahill, god rest his soul, made one of the most daring insights into the human psyche since Encino Man. his beautiful story unravels around a drug squad cop McClure, which is a name synonymous with a character from the simpsons who also happens to be an actor! said cop delves deep into the underworld that is high school drug taking, and discovers a gang war to rival that of Police Academy 1, and i mean the one where Jones is racially vilified by his new partner, but manages to come out with some of the funniest sounds you will EVER HEAR.<br /><br />Cahill's grasp of effects, both visual and aural is electrifying, the slight pause between action on screen and from the speakers adds to the drama that is snitch'd, a real gritty like underground thriller. also, kudos to his brilliant use of makeup, such as the supremely convincing burn marks a gang member suffers in his showdown with an indoor barbecue! YUCK! i feel the world of film is much less from James' passing, his memory will linger on and on and on, reborn with every passing mention of his flagship production, Snitch'd. his insightful director's commentary released a coke-hit up the nose of any discerning film goer, truly appropriate with the harsh reality that is life on the streets, captured in all the beauty of a roughneck punk knocking over a rubbish bin in a brawl.<br /><br />but i ask you, why did the big bosses swimming pool look so cheap? i'll tell you why, because thats life in Santa Ana baby, its not all drive bys and hastily constructed principle's offices, oh no. there are some folk who must infiltrate the soft, tattooed underbelly of street life in LA to kick their way through in moves that would not seem out of place at a School For Special Children's production of Double Dragon: The Play.<br /><br />the only qualm i have with this film, is that there was never a sequel made. come on Steven Spielberg, come on George Lucas, come on guy that made revenge of the nerds 1 through 23, how hard could it be to step it up a notch and pay tribute to this great man, James Cahill.<br /><br />he discovered Eva Longoria you know. oh yeah, that he did.<br /><br />Jonah\",\n",
      "       b'I saw this movie twice through a pentecostal church my family attended in Nanaimo BC in the 1970\\'s. I was of the tender age of 6, my brother 4, then again when I was 8 my brother 6. This movie terrified my brother and I and shaped how we viewed the world with distrust. It wasn\\'t just the movie, but it was also the philosophy that engulfs so many \"christians\" about the \"mark of the beast\"and the rapture. This movie, the church, and a volatile neglectful upbringing, lead to severe paranoia towards the future. For years, I lived under the delusional affects of the church and fear of being forgotten by Christ. I am now 40 years old. Went through years of counseling. I once explained to a psychiatrist this movie and the belief system of the church and family. I was pegged with a delusional disorder. I actually began to believe this, it was my brother who reminded me, that this cultic philosophy actually happened. I no longer fear the future, I have come to terms with the fear injected into it\\'s members by the church. I have taken this experience to fulfill a purpose, I am nearing my licensure as a Psychologist specializing in childhood trauma.',\n",
      "       b\"Ok so I was bored and I watched it all the way through.<br /><br />This film is mild, inoffensive and lacklustre. The story is so sugary it rots your teeth on the opening titles. A tail of two 'traumatised' children learning about 'God' the fairy story way which frankly left me rather traumatised. It uses the Irish 'blarney' in such a stereotypical way one hopes no true Irish ever see it. Aimed at children who frankly would switch off after the first attempt at an 'OIRISH' accent. All in all why do they pump these out.\",\n",
      "       b'Thanks for killing the franchise with this turkey, John Carpenter and Tommy Lee Wallace. This movie sucks on so many levels it\\'s pathetic. The first VAMPIRES was fun, but this low budget retread makes me yawn.<br /><br />Jon Bon Jovi (the poor man\\'s Kevin Bacon) drives around Mexico with a surfboard housing a hidden compartment holding his vampire killing gear ala Antonio Banderas\\'s guitar case in DESPERADO. He picks up some lame \"hunters\" along the way (including an annoyingly feminist infected girl who takes pills to keep from turning into a vampire), and they set out to stop some female master vampire who is given no backstory and so we could care less about her or her quest (to walk in the sunlight by stealing the Black Cross and performing a ritual to allow her to do so). If you\\'ve seen the first VAMPIRES, you\\'ve already seen this, and done much better.<br /><br />John Carpenter has been responsible for a lot of bad movies lately. Frankly, I think he\\'s past his prime and incapable of making another horror classic. The only decent film he\\'s done since THEY LIVE (1987) is VAMPIRES. Everything else is complete crap, right up until the unbelievably cheap looking and retarded GHOSTS OF MARS... and now this waste of celluloid. Where are more greats like ASSAULT ON PRECINCT 13, HALLOWEEN (1), ESCAPE FROM NEW YORK and THE THING?<br /><br />Carpenter crony Wallace proves he can\\'t write his way out of a paper bag with his paper-thin script packed with yawns, groans and recycled gags from the original. Did I mention I hated every character in the movie? There was not a single memorable character in the whole film. How does that happen? This film has nothing to recommend it. Not even the DVD presentation is good; the menu looks awful.<br /><br />By comparison, JASON X: \"FRIDAY THE 13th IN SPACE\" was a masterpiece. Now that is how you make a sequel and (re)energize a franchise, ladies and germs, as well as create an exciting DVD menu.',\n",
      "       b\"I watched this movie 11 years ago in company with my best female friend. I got my judgment teeth pulled out so I didn't feel very good.<br /><br />I ended up liking it big time. It's a hard watch if you take in account that it deals with friendship, unwanted betrayal, power, money, drug traffic, and the extreme hard situation that deals with living in a foreign jail.<br /><br />The acting is on it's prime level. Two of the women that I lust the most star and that's a good thing. Claire Danes is as cute and charming as always while Kate Beckinsale is extremely hot and delivers a fine performance. Bill Pullman is also great and demonstrates his histrionic qualities.<br /><br />There are many plot twists to dig from and make it an interesting visual experience. Plus it shows the difficult times at Thailand.<br /><br />This is an underrated movie. Not many films like this one have come up in recent history. It should make you reflex about many things...\",\n",
      "       b\"I've said this in other reviews, without a story, you can give the audience all the smoke and mirrors you want, still no one will give a damn.<br /><br />The director seems to have a great eye for 30s art deco (which I love), and I think the idea of using all digital backgrounds and such could indeed be the wave of the future in movie making. However, it's obvious the director got so interested in the digital rendering of his movie, he forgot to film many scenes which would have enormously helped this surprisingly thinned-plotted film. (SPOILER) For crying out loud, they forgot to have a villain in this thing! OK they have one, but he's been dead for 20 years by the time the movie takes place. Conran misses the point of HAVING a villain. As far as action goes, well let's see, Sky Captain (Law) shoots down ONE robot, two or three of the flapping wing airplanes (before Dex (Ribisi) tells him to stop shooting them down!!!), and a couple robots, but mostly spends his time looking dashing and getting others to fight his battles for him. Paltrow as Polly or Peggy or Punky or whatever is totally wasted in this movie (the reviewer who comments on hers and Law's lack of chemistry is so right) and I for one got a little sick of seeing repeated shots of the top of her camera, showing she ONLY HAS TWO SHOTS LEFT, both of which she wastes subsequently in the movie, one uncomically, one quite funny, although I saw it coming from 70 years away. No one except Law and Paltrow have any significant time on screen, and that's the movie's real flaw. An audience doesn't identify with robots, they need a hero to root for, and a visible, despicable villain to hate. Without that, plus a good engaging story, all the CG in the world won't help.\",\n",
      "       b\"Moron and girlfriend conduct some ritual to resurrect the dead, in attempt to prove that the dead can not be brought back to life. Not surprisingly, they do resurrect a dead soul who commences chopping them up with an axe, and the next day some college aged people are telling the story around a campfire. The guy with the axe turns up and starts hacking up the idiots telling the story. The group calls the cops, the cop sees blood splattered all over and thinks it's a mountain lion(!?) and soon after is axed by some deformed killer who may or may not be a ghost.<br /><br />Moronic little splatter movie which was filmed in broad daylight but where several characters are carrying flashlights and talking as though it were the middle of the night, and wanting to send up a signal flare to attract attention. One guy has a gun in one hand and bullets in the other but doesn't bother to load it, then after he finally loads it, he has several opportunities to shoot the killer but doesn't bother to, because that would end the movie too early. Then he throws the gun away! Also detrimental is characters who show no emotion and don't look the least bit concerned after their friends are chopped up into pieces and lousy effects (the human heart looks like a piece of chicken meat, the car blown up at the end clearly was a model car) and awful dialogue and some really ugly female nudity doesn't help. And in the end it tries to get away with it's incoherence by saying that it was all the invention of the same college aged people telling campfire stories at the start of this movie. <br /><br />Then the killer turns up for real in the last scene hacks them into pieces. Again.<br /><br />Mediocre of it's kind, good only for some unintended laughs.<br /><br />*1/2 out of ****\",\n",
      "       b\"This is easily the worst Ridley Scott film. Ridley Scott is a wonderful director. But this film is a black mark on his career. Demi Moore and Viggo Mortensen, both totally miscast in an overaggressive film about a girl going to the army. Very stupid. And there is never one scene that is convincing in any way. It is really not difficult to make a film such as this. Everything the crew makes could have been an idea of just anybody. The writers didn't have much inspiration either; many foolish dialogs that made no sense at all; and some brainless action. I strongly recommend to stay away from this rubbish. I hope that the many talented persons involved in this project realize this type of film does not deserve their attention, and that in the future they will work on more honorable and more intelligent movies than this useless mess.\",\n",
      "       b\"Partially from the perceived need, one feels, to include a conventional love story in the plot to make the film more marketable to a 1950's movie-going public. <br /><br />The film starts with some wickedly funny characterizations of the upper-class bureaucrats running the Foreign Office --- the British are pilloried in the way that only the British can pillory themselves. But after that, the film loses its way in a conventional farcical plot. Terry-Thomas watchable as always, but the great talent in the cast (Peter Sellers, et al) is largely wasted.<br /><br />A diverting, but not great film.\",\n",
      "       b'If you are one of the people who finds \"According to Jim\" great television comedy, this is going to rock your world. And might I add, kudos for proving that good talent, good writing and a charismatic star are all you really need on any network other than ABC, which prefers to air crap like Jim Belushi\\'s show year after year.<br /><br />\"K-911\" is a big, steaming, brown, German shepherd-sized \"thank you\" for all of the geniuses who loved the first movie. It\\'s exactly what fans of that film and the lesser Belushi deserve. Jim\\'s comedic chops and choice in projects are never far behind his ability to butcher a blues standard. Look for him to try to showcase all of his diverse lacks of talent into every project he hurls at the public like a surly zoo chimpanzee.<br /><br />If you enjoy Jim\\'s work, this movie is your reward.',\n",
      "       b\"This is the first 10 out of 10 that I've given any movie. What made this movie so good for me? Constant action - there isn't any slow parts, great acting, smart writing. I also liked the filming style where the shakiness and different angles just made it feel like you are a part of the scene. Finally, I get to see an action movie that doesn't try to please all sectors of the public (i.e. there's no forced romance).<br /><br />I liked the first two Bourne movies, but I loved this one.<br /><br />Warning - after watching this movie, you will be full of adrenaline and you may want to calm down a bit before driving your car!\",\n",
      "       b'I looked forward to seeing this movie when it came out, since I was a huge SNL fan. When my boyfriend and I went to see it, the people coming out of the early show were yelling, \"Don\\'t waste your money!\" But of course we had to find out for ourselves.<br /><br />While there were a few funny bits (Laser Bra 2000, Root Boy Slim), most of it felt like it could have been severely edited down to an amusing 1 hour show. It was pretty bad.<br /><br />When the opera singer came on, many people got up and walked out. This made me laugh, because I realized that O\\'Donoghue was just pressing people\\'s buttons on purpose with this movie. Or else he was just insane. Whatever - you don\\'t need to waste your time watching it, it\\'s that bad.',\n",
      "       b\"'The Luzhin Defence' is a good film with fine central performances, but too much of the novel and not enough of the filmmaker's craft shines through. It felt through most of the film that the characters just helped to push the narrative along. Marlene Gorris could perhaps have examined the psyche of Luzhin, rather than depicting him as a tortured innocent victim torn apart by the cruel motives of others.<br /><br />Adapting literature for the screen is clearly a difficult task, especially a novel written in the early 20th century. This film does not go deeply enough into the relationship between Luzhin and Natalia. Natalia's rift with her mother comes across a churlish disagreement by the mother rather than a dramatic flashpoint in the film. I felt that I was put through Luzhin's torment and eventual tragic end, without being given the pleasure of having his unusual and complex personality unravelled. However, this was a moving and enjoyable film but certainly not a great one.\",\n",
      "       b\"With stunning cinematography and a thread of Kafkaesque absurdity, this movie had me from the simple yet fascinating opening scene. The movie plays much like a dream, and I think that may be why people either hate it or love it. Characters are drawn superficially and the story itself is slight and perhaps a little pointless. But these are failings of the movie but conscious choices. The film works isn't trying to work as history, but rather is a deconstruction of 1940s war movies. <br /><br />I would have trouble arguing that there was much real substance to the movie, but the movie is such a cinematic wonder that I was completely swept away. This is one of the most beautifully filmed movies ever, and there is a wild imagination in its style. I can completely understand why people would hate it, but I give it 9/10.\",\n",
      "       b\"Because others have gone to the trouble of summarizing the plot, I'd like to mention a few points about this film. There may be spoilers here; I don't care enough to filter them out.<br /><br />- Given the film's low budget, the creature design was quite good. It's actually nice to see a direct-to-video horror film that's not slathered with awful CGI. Unfortunately the digital film quality's quite grainy in places, and it's most noticeable in the well-lit white halls of the asylum.<br /><br />- Ridiculous lighting design plagues parts of this film, to say nothing of the variations in the passage of time. I understand the director might have been trying to simulate dementia, but in order for this to be effective consistent time flow needed to be established. As-is, it merely seems amateurish.<br /><br />- Plot twists were numerous but consistently predictable. I neither had a doubt in my mind of the identity of the robed cultists, nor of the fact that some kind of lame evil-trumps-good development would surface at the end.<br /><br />- This may seem like quibbling, but characters in this film reliably fail to employ any kind of common sense. First of all, regulatory commissions would be all over a mental health center that unilaterally declared all patient and employee deaths cardiac arrest-induced. Why would the head psychiatrist also be capable of performing autopsies? Why wasn't a plot point made of these impressive qualifications, or of his introduction to his odd choice of religion? What's the background? What's supposed to make us care about anyone in this? And just as importantly, who in their right mind would go through the introduction to the place, see everything that was so frighteningly wrong with it, and then conclude that it was still a fine place to pursue a residency? This film didn't even respect its characters enough to give their intelligence the benefit of the doubt.<br /><br />Bottom line: See The Wicker Man instead.\",\n",
      "       b'The only reason that I did not give this 10 stars was the DVD format-no menus, extras, etc. However, if you have ever had a dream to do something with your life, this film is for you. If you believe in yourself and your dream do not let anyone or anything stop you. This is one of the most life-affirming films that I have ever seen. And magical. The acting is superb, the plot serves the purpose, and the opening sequence is fantastic. This is one of those films that \"cult\" status used to be about. I have recommended this film to all of my friends. Some love it, some can\\'t finish it. Whenever I think, or feel , that something is impossible I think about Alan Arkin\\'s role in this film. Sure wish he\\'d make more films.',\n",
      "       b'I watched this last night with low expectations. The reasons being, I don\\'t usually like \"made for TV\" movies and rarely have I liked \"cast reunion\" movies. But, the critic in the Los Angeles Times seemed to like this, so I gave it a chance. I\\'m glad I did. It was pretty good. Adam West and Burt Ward reunite as themselves. But, in a way, they were acting as their \"Batman and Robin\" selves. They were being campy and not taking themselves, or this movie too seriously. The movie starts out with them searching for the \"George Barris\" designed Batmobile, that someone stole before it was to be auctioned off for an orphan\\'s home. While, they are searching for the car, they are also reminiscing about the series that they did together. This is told in flashback. It was well done. The actors that they got, for the younger Burt Ward and Adam West were dead on. And, for a TV movie, it got down to the nitty-gritty about their real behavior on and off the screen. I give this one a 9/10, I liked it that much.',\n",
      "       b\"The first part of Grease with John Travolta and Olivia Newton John is one of the best movie for teens, This one is a very bad copy. The change is only in the sex. In the first one the good one was Sandy, here it's Michael. I prefer to watch the first Grease.\",\n",
      "       b\"This is a pretty decent example of film noir. The setting is the early 50's with the Communists trying to steal weapon secrets from the US Government.<br /><br />Richard Widmark is the suave pickpocket without scruples. He gives a pretty decent performance but there is nothing A-List about him. The interesting thing was that he was not only an anti-hero but through most of the film, an unlikeable anti-hero. That is not very normal. Jean Peters gave a so-so performance as the hooker with the heart of gold. That great character actress Thelma Ritter shines as the stool-pigeon.<br /><br />The plot had its fair share of twists and turns, wisecracks and tough talk. There is a fight scene near the end of the movie (in the subway station) that was pretty gritty and exciting.<br /><br />I think noir fans (like myself) will enjoy this film. For non-noir viewers, it may seem a little dated and the whole Commie thing a tad overdone.\",\n",
      "       b\"I watched this movie expecting what I got: good sci-fi cowboy stuff. What really surprised me was that Kurt Russell did such a great job with an extremely limited role.<br /><br />Imagine trying to act under these two restraints: you have hardly any dialogue, and because you are playing a hardass, military robot, you are not allowed to show emotions using facial expressions! Howzat? Kinda like asking a diva to perform a great aria while gagged and duct-taped. In spite of being verbally and expressionally handcuffed, Russell pulls off an incredible characterization. His robot becomes human, in spite of the constraints. Great job!<br /><br />As usual, Jason Isaacs insures that he will go down in history as a great portrayer of the consummate villain--the one you'd love to see drawn and quartered. Connie Nielsen was sweet, soft, motherly, and gorgeous. I'm not sure how much of my impression is based on her acting and how much on her physical beauty, but it was hard to take one's eyes off her. Unfortunately, Gary Busey's role was too small and limited. <br /><br />Much of the plot is quite standard, with a fair amount of weaknesses, but as it does have a sci-fi comic book feeling, I don't see what's wrong with a few weaknesses. By the end of the story the good guy wins, and the appreciative audience receives a great deal of emotional satisfaction. Yes!<br /><br />The sort of feeb who thinks that Russell didn't do a good job of acting is the same sort of feeb who missed the whole point.\",\n",
      "       b'This movie was charming. An accountant wants more from life than the approved conventional success. What makes it work so well, and makes it so different from the standard dance movie is that it really isn\\'t about becoming \"Great\" it is simply about finding a way to express one\\'s self. The big triumph at the end is not the winning of a contest, not the discovery of a whole new life style, but the simple joy of doing what you want to fulfill the other parts of your life. No one is discovering their passion, they are finding their quiet soul.<br /><br />The Japanese background makes the subtle oppression and \"secret life\" of ballroom dancing both understandable and personal. We can all see ourselves in the everyman.'],\n",
      "      dtype=object)>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "       0, 1, 1, 0, 1, 1, 0, 1, 1, 1], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "for item in train_set.take(1):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea34544",
   "metadata": {},
   "source": [
    "### d.\n",
    "_Exercise: Create a binary classification model, using a TextVectorization layer to preprocess each review. If the TextVectorization layer is not yet available (or if you like a challenge), try to create your own custom preprocessing layer: you can use the functions in the tf.strings package, for example lower() to make everything lowercase, regex_replace() to replace punctuation with spaces, and split() to split words on spaces. You should use a lookup table to output word indices, which must be prepared in the adapt() method._\n",
    "\n",
    "Let's first write a function to preprocess the reviews, cropping them to 300 characters, converting them to lower case, then replacing <br /> and all non-letter characters to spaces, splitting the reviews into words, and finally padding or cropping each review so it ends up with exactly n_words tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7947d179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50), dtype=string, numpy=\n",
       "array([[b'it', b's', b'a', b'great', b'great', b'movie', b'i', b'loved',\n",
       "        b'it', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>'],\n",
       "       [b'it', b'was', b'terrible', b'run', b'away', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>']], dtype=object)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(X_batch, n_words=50):\n",
    "    shape = tf.shape(X_batch) * tf.constant([1, 0]) + tf.constant([0, n_words])\n",
    "    Z = tf.strings.substr(X_batch, 0, 300)\n",
    "    Z = tf.strings.lower(Z)\n",
    "    Z = tf.strings.regex_replace(Z, b\"<br\\\\s*/?>\", b\" \")\n",
    "    Z = tf.strings.regex_replace(Z, b\"[^a-z]\", b\" \")\n",
    "    Z = tf.strings.split(Z)\n",
    "    return Z.to_tensor(shape=shape, default_value=b\"<pad>\")\n",
    "\n",
    "X_example = tf.constant([\"It's a great, great movie! I loved it. <br />\", \"It was terrible, run away!!!\"])\n",
    "preprocess(X_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c98d2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<pad>',\n",
       " b'it',\n",
       " b'great',\n",
       " b's',\n",
       " b'a',\n",
       " b'movie',\n",
       " b'i',\n",
       " b'loved',\n",
       " b'was',\n",
       " b'terrible',\n",
       " b'run',\n",
       " b'away']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_vocabulary(data_sample, max_size=1000):\n",
    "    preprocessed_reviews = preprocess(data_sample).numpy()\n",
    "    counter = Counter()\n",
    "    for words in preprocessed_reviews:\n",
    "        for word in words:\n",
    "            if word != b\"<pad>\":\n",
    "                counter[word] += 1\n",
    "    return [b\"<pad>\"] + [word for word, count in counter.most_common(max_size)]\n",
    "\n",
    "get_vocabulary(X_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f8d092",
   "metadata": {},
   "source": [
    "Now we are ready to create the TextVectorization layer. Its constructor just saves the hyperparameters (max_vocabulary_size and n_oov_buckets). The adapt() method computes the vocabulary using the get_vocabulary() function, then it builds a StaticVocabularyTable (see Chapter 16 for more details). The call() method preprocesses the reviews to get a padded list of words for each review, then it uses the StaticVocabularyTable to lookup the index of each word in the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd067944",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextVectorization(keras.layers.Layer):\n",
    "    def __init__(self, max_vocabulary_size=1000, n_oov_buckets=100, dtype=tf.string, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        self.max_vocabulary_size = max_vocabulary_size\n",
    "        self.n_oov_buckets = n_oov_buckets\n",
    "\n",
    "    def adapt(self, data_sample):\n",
    "        self.vocab = get_vocabulary(data_sample, self.max_vocabulary_size)\n",
    "        words = tf.constant(self.vocab)\n",
    "        word_ids = tf.range(len(self.vocab), dtype=tf.int64)\n",
    "        vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
    "        self.table = tf.lookup.StaticVocabularyTable(vocab_init, self.n_oov_buckets)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        preprocessed_inputs = preprocess(inputs)\n",
    "        return self.table.lookup(preprocessed_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b633c3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50), dtype=int64, numpy=\n",
       "array([[ 1,  3,  4,  2,  2,  5,  6,  7,  1,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 1,  8,  9, 10, 11,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0]])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorization = TextVectorization()\n",
    "\n",
    "text_vectorization.adapt(X_example)\n",
    "text_vectorization(X_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2a57ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create another TextVectorization layer, build the Vocabulary for the full train_set\n",
    "max_vocabulary_size = 1000\n",
    "n_oov_buckets = 100\n",
    "\n",
    "sample_review_batches = train_set.map(lambda review, label: review)\n",
    "sample_reviews = np.concatenate(list(sample_review_batches.as_numpy_iterator()),\n",
    "                                axis=0)\n",
    "\n",
    "text_vectorization = TextVectorization(max_vocabulary_size, n_oov_buckets,\n",
    "                                       input_shape=[])\n",
    "text_vectorization.adapt(sample_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12c4a496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50), dtype=int64, numpy=\n",
       "array([[  9,  14,   2,  64,  64,  12,   5, 256,   9,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  9,  13, 269, 530, 334,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test with x_sample\n",
    "text_vectorization(X_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0aeb14b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<pad>', b'the', b'a', b'of', b'and', b'i', b'to', b'is', b'this', b'it']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 most common words in vocab\n",
    "text_vectorization.vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd3d20ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[2., 2., 0., 1.],\n",
       "       [3., 0., 2., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now to build our model we will need to encode all these word IDs somehow. \n",
    "## One approach is to create bags of words: for each review, and for each word in the vocabulary, \n",
    "## we count the number of occurences of that word in the review. For example:\n",
    "\n",
    "simple_example = tf.constant([[1, 3, 1, 0, 0], [2, 2, 0, 0, 0]])\n",
    "tf.reduce_sum(tf.one_hot(simple_example, 4), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002d823a",
   "metadata": {},
   "source": [
    "The first review has 2 times the word 0, 2 times the word 1, 0 times the word 2, and 1 time the word 3, so its bag-of-words representation is [2, 2, 0, 1]. Similarly, the second review has 3 times the word 0, 0 times the word 1, and so on. Let's wrap this logic in a small custom layer, and let's test it. We'll drop the counts for the word 0, since this corresponds to the <pad> token, which we don't care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4f92d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BagOfWords(keras.layers.Layer):\n",
    "    def __init__(self, n_tokens, dtype=tf.int32, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        self.n_tokens = n_tokens\n",
    "    def call(self, inputs):\n",
    "        one_hot = tf.one_hot(inputs, self.n_tokens)\n",
    "        return tf.reduce_sum(one_hot, axis=1)[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "732c18c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[2., 0., 1.],\n",
       "       [0., 2., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "bag_of_words = BagOfWords(n_tokens=4)\n",
    "bag_of_words(simple_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2481c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the BagOfWord with right vocabulary size for the training set\n",
    "n_tokens = max_vocabulary_size + n_oov_buckets + 1 # add 1 for <pad>\n",
    "bag_of_words = BagOfWords(n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64489a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "     67/Unknown - 1s 2ms/step - loss: 0.6589 - accuracy: 0.6012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 17:55:42.747647: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 4s 4ms/step - loss: 0.5399 - accuracy: 0.7213 - val_loss: 0.5088 - val_accuracy: 0.7407\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.4670 - accuracy: 0.7720 - val_loss: 0.5147 - val_accuracy: 0.7365\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.4140 - accuracy: 0.8081 - val_loss: 0.5178 - val_accuracy: 0.7407\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.3404 - accuracy: 0.8574 - val_loss: 0.5457 - val_accuracy: 0.7339\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.2538 - accuracy: 0.9081 - val_loss: 0.5866 - val_accuracy: 0.7355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8004254610>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## define the model with text_vector layer, bagOfWord layer\n",
    "model = keras.models.Sequential([\n",
    "    text_vectorization,\n",
    "    bag_of_words,\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2a1f86",
   "metadata": {},
   "source": [
    "We get about 73.5% accuracy on the validation set after just the first epoch, but after that the model makes no significant progress. We will do better in Chapter 16. For now the point is just to perform efficient preprocessing using tf.data and Keras preprocessing layers.\n",
    "\n",
    "### e.\n",
    "_Exercise: Add an Embedding layer and compute the mean embedding for each review, multiplied by the square root of the number of words (see Chapter 16). This rescaled mean embedding can then be passed to the rest of your model._\n",
    "\n",
    "To compute the mean embedding for each review, and multiply it by the square root of the number of words in that review, we will need a little function. For each sentence, this function needs to compute $M x \\sqrt{N}$, where *M* is the mean of all the word embeddings in the sentence (excluding padding tokens), and *N* is the number of words in the sentence (also excluding padding tokens). We can rewrite *M* as $ \\frac{S}{N} $, where *S* is the sum of all word embeddings (it does not matter whether or not we include the padding tokens in this sum, since their representation is a zero vector). So the function must return $\\displaystyle{M x \\sqrt{N} = \\frac{S}{N} x \\sqrt{N} = \\frac{S}{\\sqrt{N}}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0508adf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[3.535534 , 4.9497476, 2.1213205],\n",
       "       [6.       , 0.       , 0.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_mean_embedding(inputs):\n",
    "    not_pad = tf.math.count_nonzero(inputs, axis=-1)\n",
    "    n_words = tf.math.count_nonzero(not_pad, axis=-1, keepdims=True)    \n",
    "    sqrt_n_words = tf.math.sqrt(tf.cast(n_words, tf.float32))\n",
    "    return tf.reduce_sum(inputs, axis=1) / sqrt_n_words\n",
    "\n",
    "another_example = tf.constant([[[1., 2., 3.], [4., 5., 0.], [0., 0., 0.]],\n",
    "                               [[6., 0., 0.], [0., 0., 0.], [0., 0., 0.]]])\n",
    "compute_mean_embedding(another_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6a07402",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we're ready to train our final model. It's the same as before, except we replaced the BagOfWords layer \n",
    "## with an Embedding layer followed by a Lambda layer that calls the compute_mean_embedding layer:\n",
    "\n",
    "embedding_size = 20\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    text_vectorization,\n",
    "    keras.layers.Embedding(input_dim=n_tokens,\n",
    "                           output_dim=embedding_size,\n",
    "                           mask_zero=True), # <pad> tokens => zero vectors\n",
    "    keras.layers.Lambda(compute_mean_embedding),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a205395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 4s 4ms/step - loss: 0.5531 - accuracy: 0.7159 - val_loss: 0.5108 - val_accuracy: 0.7411\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.4952 - accuracy: 0.7556 - val_loss: 0.5088 - val_accuracy: 0.7402\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.4864 - accuracy: 0.7611 - val_loss: 0.5090 - val_accuracy: 0.7404\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.4790 - accuracy: 0.7638 - val_loss: 0.5044 - val_accuracy: 0.7423\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.4713 - accuracy: 0.7646 - val_loss: 0.5159 - val_accuracy: 0.7387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f800440c310>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec19d995",
   "metadata": {},
   "source": [
    "The model is not better using embeddings (but we will do better in Chapter 16). The pipeline looks fast enough (we optimized it earlier).\n",
    "\n",
    "### g.\n",
    "Use TFDS to load the same dataset more easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad9ba31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 18:17:45.757379: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /home/chuongnet/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bab50d261ad49ed897a601bbc5350a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2f906b02c04986ade0768bc08611b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/chuongnet/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteMTJR1A/imdb_reviews-trai"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/chuongnet/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteMTJR1A/imdb_reviews-test"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised examples...:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/chuongnet/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteMTJR1A/imdb_reviews-unsu"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to /home/chuongnet/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "datasets = tfds.load(name=\"imdb_reviews\")\n",
    "train_set, test_set = datasets[\"train\"], datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ea24eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\", shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 18:26:15.120751: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for example in train_set.take(1).cache():\n",
    "    print(example[\"text\"])\n",
    "    print(example[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d673edc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
